{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AVRjbw3ShSco"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1314] A required privilege is not held by the client: '/kaggle/input' -> '..\\\\input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(KAGGLE_WORKING_PATH, \u001b[38;5;241m0o777\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 31\u001b[0m   \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKAGGLE_INPUT_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m..\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_is_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1314] A required privilege is not held by the client: '/kaggle/input' -> '..\\\\input'"
     ]
    }
   ],
   "source": [
    "\n",
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
    "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import unquote, urlparse\n",
    "from urllib.error import HTTPError\n",
    "from zipfile import ZipFile\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "CHUNK_SIZE = 40960\n",
    "DATA_SOURCE_MAPPING = 'aiml-general-championship:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F71608%2F7895811%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240731%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240731T160003Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D96c5df5c9599d65577fdc4bd9081f0110dc50c675b0872c7913c5c9f05300cb0ebc74c79f07112231e488864d1c9ba1c0e7d9e72732033640ec443ecf3d0663434587c6590c586e34e4bf578a6b73c46b8f35ab28bf7f9a7792bf9e7e925ddf5ea1294e979536c888f6c066979cbb9fab480ae49a52d9b2b757a6c4eb01a2db472c047cb127c0e2db2ccd400d9ac441b93194411e3c0535ee581a40288b6d9e4a8bbe5036fdfd7691d039f0873a125c48c887b35ca418352079a8499ab6eb54aee3dda514ce4373208d9c14fa4865cff045c92bbc182e85c5944030cea63a84dd1dc8b8bf44057e14d6f3a70d514833b3003686a1769b709bbed20e50cfc1739'\n",
    "\n",
    "KAGGLE_INPUT_PATH='/kaggle/input'\n",
    "KAGGLE_WORKING_PATH='/kaggle/working'\n",
    "KAGGLE_SYMLINK='kaggle'\n",
    "\n",
    "!umount /kaggle/input/ 2> /dev/null\n",
    "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
    "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
    "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
    "\n",
    "try:\n",
    "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
    "except FileExistsError:\n",
    "  pass\n",
    "try:\n",
    "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
    "except FileExistsError:\n",
    "  pass\n",
    "\n",
    "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
    "    directory, download_url_encoded = data_source_mapping.split(':')\n",
    "    download_url = unquote(download_url_encoded)\n",
    "    filename = urlparse(download_url).path\n",
    "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
    "    try:\n",
    "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
    "            total_length = fileres.headers['content-length']\n",
    "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
    "            dl = 0\n",
    "            data = fileres.read(CHUNK_SIZE)\n",
    "            while len(data) > 0:\n",
    "                dl += len(data)\n",
    "                tfile.write(data)\n",
    "                done = int(50 * dl / int(total_length))\n",
    "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
    "                sys.stdout.flush()\n",
    "                data = fileres.read(CHUNK_SIZE)\n",
    "            if filename.endswith('.zip'):\n",
    "              with ZipFile(tfile) as zfile:\n",
    "                zfile.extractall(destination_path)\n",
    "            else:\n",
    "              with tarfile.open(tfile.name) as tarfile:\n",
    "                tarfile.extractall(destination_path)\n",
    "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
    "    except HTTPError as e:\n",
    "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
    "        continue\n",
    "    except OSError as e:\n",
    "        print(f'Failed to load {download_url} to path {destination_path}')\n",
    "        continue\n",
    "\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:28.452535Z",
     "iopub.status.busy": "2024-04-10T17:36:28.451851Z",
     "iopub.status.idle": "2024-04-10T17:36:28.462761Z",
     "shell.execute_reply": "2024-04-10T17:36:28.461763Z",
     "shell.execute_reply.started": "2024-04-10T17:36:28.452504Z"
    },
    "id": "c40b9da2-c586-4fd9-a3ca-5bfd4b55c8e6"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# python libraties\n",
    "import os, cv2,itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "# pytorch libraries\n",
    "import torch\n",
    "from torch import optim,nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import models,transforms\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ensure results are reproducible\n",
    "np.random.seed(10)\n",
    "torch.manual_seed(10)\n",
    "torch.cuda.manual_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:28.948227Z",
     "iopub.status.busy": "2024-04-10T17:36:28.947851Z",
     "iopub.status.idle": "2024-04-10T17:36:28.954911Z",
     "shell.execute_reply": "2024-04-10T17:36:28.95406Z",
     "shell.execute_reply.started": "2024-04-10T17:36:28.948196Z"
    },
    "id": "f5a8f919-a3b2-4855-92eb-eae26a2d7c67"
   },
   "outputs": [],
   "source": [
    "data_dir = \"/kaggle/input/aiml-general-championship\"\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3a59dac0-0469-4277-97cf-91d3184db2f8"
   },
   "source": [
    "img_data_dir = data_dir + r\"/KCDH2024_Training_Input_10K/KCDH2024_Training_Input_10K\"\n",
    "all_image_path = glob(os.path.join(img_data_dir, '*.jpg'))\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}  # key - image filename,   value - path to image\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'dermatofibroma',\n",
    "    'bkl': 'Benign keratosis-like lesions ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:29.021439Z",
     "iopub.status.busy": "2024-04-10T17:36:29.021123Z",
     "iopub.status.idle": "2024-04-10T17:36:29.090083Z",
     "shell.execute_reply": "2024-04-10T17:36:29.089393Z",
     "shell.execute_reply.started": "2024-04-10T17:36:29.021411Z"
    },
    "id": "0f8a1675-e8fe-4073-a708-81d5ff299e25"
   },
   "outputs": [],
   "source": [
    "len(imageid_path_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:29.091819Z",
     "iopub.status.busy": "2024-04-10T17:36:29.091557Z",
     "iopub.status.idle": "2024-04-10T17:36:29.097422Z",
     "shell.execute_reply": "2024-04-10T17:36:29.09652Z",
     "shell.execute_reply.started": "2024-04-10T17:36:29.091795Z"
    },
    "id": "fca57305-c2bb-46a1-8334-26860f85c74b"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(imageid_path_dict[\"ISIC_0024308\"])\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:29.143311Z",
     "iopub.status.busy": "2024-04-10T17:36:29.142712Z",
     "iopub.status.idle": "2024-04-10T17:36:29.1591Z",
     "shell.execute_reply": "2024-04-10T17:36:29.158324Z",
     "shell.execute_reply.started": "2024-04-10T17:36:29.143284Z"
    },
    "id": "24c97e68-8a4d-47ef-8568-6301572606e9"
   },
   "outputs": [],
   "source": [
    "def compute_img_mean_std(image_paths):\n",
    "    \"\"\"\n",
    "        computing the mean and std of three channel on the whole dataset,\n",
    "        first we should normalize the image from 0-255 to 0-1\n",
    "    \"\"\"\n",
    "\n",
    "    img_h, img_w = 224, 224              # Size to resize..\n",
    "    imgs = []\n",
    "    means, stdevs = [], []\n",
    "\n",
    "    for i in tqdm(range(len(image_paths))):\n",
    "        img = cv2.imread(image_paths[i])\n",
    "        img = cv2.resize(img, (img_h, img_w))\n",
    "        imgs.append(img)\n",
    "\n",
    "    imgs = np.stack(imgs, axis=3)\n",
    "    print(imgs.shape)\n",
    "\n",
    "    imgs = imgs.astype(np.float32) / 255.\n",
    "\n",
    "    for i in range(3):\n",
    "        pixels = imgs[:, :, i, :].ravel()  # resize to one row\n",
    "        means.append(np.mean(pixels))\n",
    "        stdevs.append(np.std(pixels))\n",
    "\n",
    "    means.reverse()  # BGR --> RGB\n",
    "    stdevs.reverse()\n",
    "\n",
    "    print(\"normMean = {}\".format(means))\n",
    "    print(\"normStd = {}\".format(stdevs))\n",
    "    return means,stdevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:29.318469Z",
     "iopub.status.busy": "2024-04-10T17:36:29.317736Z",
     "iopub.status.idle": "2024-04-10T17:36:29.326369Z",
     "shell.execute_reply": "2024-04-10T17:36:29.325422Z",
     "shell.execute_reply.started": "2024-04-10T17:36:29.318438Z"
    },
    "id": "f7fc46fa-902e-4f03-8121-bf9713b2ce46"
   },
   "outputs": [],
   "source": [
    "# means , stdevs = compute_img_mean_std(all_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:29.449578Z",
     "iopub.status.busy": "2024-04-10T17:36:29.449257Z",
     "iopub.status.idle": "2024-04-10T17:36:29.455682Z",
     "shell.execute_reply": "2024-04-10T17:36:29.454817Z",
     "shell.execute_reply.started": "2024-04-10T17:36:29.449552Z"
    },
    "id": "b214f0bb-9b9a-4056-87d0-2fcb3ceae02e"
   },
   "outputs": [],
   "source": [
    "# Store Values to save time in future..\n",
    "norm_mean = [0.76696384, 0.54525656, 0.56884694]\n",
    "norm_std = [0.13945772, 0.15192385, 0.16916788]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:29.59793Z",
     "iopub.status.busy": "2024-04-10T17:36:29.597639Z",
     "iopub.status.idle": "2024-04-10T17:36:29.602654Z",
     "shell.execute_reply": "2024-04-10T17:36:29.601692Z",
     "shell.execute_reply.started": "2024-04-10T17:36:29.597904Z"
    },
    "id": "951cf86b-ce11-4ffe-a8d5-05bce76a8b2f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b440bd71-d7b5-478c-ac87-6f805e6f1dc3"
   },
   "outputs": [],
   "source": [
    "lesion_db = pd.read_csv(os.path.join(data_dir, 'KCDH2024_Training_LesionGroupings.csv'))\n",
    "truth_db = pd.read_csv(os.path.join(data_dir, 'KCDH2024_Training_GroundTruth.csv'))\n",
    "\n",
    "df = pd.merge(lesion_db, truth_db, on = 'image', how = 'inner')\n",
    "df.drop(\"diagnosis_confirm_type\", axis = 1, inplace = True)\n",
    "df['path'] = df['image'].map(imageid_path_dict.get)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:29.892555Z",
     "iopub.status.busy": "2024-04-10T17:36:29.891847Z",
     "iopub.status.idle": "2024-04-10T17:36:29.950854Z",
     "shell.execute_reply": "2024-04-10T17:36:29.949959Z",
     "shell.execute_reply.started": "2024-04-10T17:36:29.892523Z"
    },
    "id": "c6b294f0-8314-4385-b301-4d2950aae9e7"
   },
   "outputs": [],
   "source": [
    "# Remove the rows not containg path to images..\n",
    "df = df[df['path'].notna()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:30.04056Z",
     "iopub.status.busy": "2024-04-10T17:36:30.039739Z",
     "iopub.status.idle": "2024-04-10T17:36:30.058737Z",
     "shell.execute_reply": "2024-04-10T17:36:30.057819Z",
     "shell.execute_reply.started": "2024-04-10T17:36:30.040528Z"
    },
    "id": "11bd67f6-cb38-4565-8ee3-8da234bc54e6"
   },
   "outputs": [],
   "source": [
    "# Convert 7 different columns of different lesisons to single ...\n",
    "\n",
    "cell_type_idx = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    cell_type_idx_row = row[\"MEL\"], row[\"NV\"], row[\"BCC\"], row[\"AKIEC\"], row[\"BKL\"], row[\"DF\"], row[\"VASC\"]\n",
    "    cell_type_idx.append(cell_type_idx_row.index(1))\n",
    "\n",
    "# Assign a new column..\n",
    "df[\"cell_type_idx\"] = cell_type_idx\n",
    "\n",
    "# Drop older columns..\n",
    "df.drop( columns = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"], inplace = True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:30.192183Z",
     "iopub.status.busy": "2024-04-10T17:36:30.191922Z",
     "iopub.status.idle": "2024-04-10T17:36:31.023926Z",
     "shell.execute_reply": "2024-04-10T17:36:31.022827Z",
     "shell.execute_reply.started": "2024-04-10T17:36:30.192159Z"
    },
    "id": "8a1af7d5-f0dc-4757-abb1-0b41eb80c4a8"
   },
   "outputs": [],
   "source": [
    "# Determine how many images are associated with each lesion_id ?\n",
    "df_undup = df.groupby('lesion_id').count()\n",
    "\n",
    "# Filter out lesion_id's that have only one image associated with it\n",
    "df_undup = df_undup[df_undup['image'] == 1]\n",
    "df_undup.reset_index(inplace=True)\n",
    "df_undup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:31.026334Z",
     "iopub.status.busy": "2024-04-10T17:36:31.025971Z",
     "iopub.status.idle": "2024-04-10T17:36:31.056521Z",
     "shell.execute_reply": "2024-04-10T17:36:31.055603Z",
     "shell.execute_reply.started": "2024-04-10T17:36:31.026301Z"
    },
    "id": "5d85effd-a57f-4333-917b-9bd71efd85f2"
   },
   "outputs": [],
   "source": [
    "df_undup = df.groupby('lesion_id').count()\n",
    "df_undup.head()\n",
    "\n",
    "# Filter out lesion_id's that have only one image associated with it\n",
    "df_undup = df_undup[df_undup['image'] == 1]\n",
    "df_undup.reset_index(inplace=True)\n",
    "df_undup[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:31.059162Z",
     "iopub.status.busy": "2024-04-10T17:36:31.058162Z",
     "iopub.status.idle": "2024-04-10T17:36:31.089869Z",
     "shell.execute_reply": "2024-04-10T17:36:31.088966Z",
     "shell.execute_reply.started": "2024-04-10T17:36:31.059129Z"
    },
    "id": "a8ac9dfc-9f52-4b5c-b8be-9d730ac9e35c"
   },
   "outputs": [],
   "source": [
    "# Identify lesion_id's that have duplicate images and those that have only one image.\n",
    "def get_duplicates(x):\n",
    "    unique_list = list(df_undup['lesion_id'])\n",
    "    if x in unique_list:\n",
    "        return 'unduplicated'\n",
    "    else:\n",
    "        return 'duplicated'\n",
    "\n",
    "# Create a new colum that is a copy of the lesion_id column\n",
    "df['duplicates'] = df['lesion_id']\n",
    "# Apply the function to this new column\n",
    "df['duplicates'] = df['duplicates'].apply(get_duplicates)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:31.091889Z",
     "iopub.status.busy": "2024-04-10T17:36:31.091571Z",
     "iopub.status.idle": "2024-04-10T17:36:38.428129Z",
     "shell.execute_reply": "2024-04-10T17:36:38.427216Z",
     "shell.execute_reply.started": "2024-04-10T17:36:31.091866Z"
    },
    "id": "b35c408f-cc71-4dd0-bf2b-836f9e4b1ebc"
   },
   "outputs": [],
   "source": [
    "df['duplicates'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:38.430182Z",
     "iopub.status.busy": "2024-04-10T17:36:38.429583Z",
     "iopub.status.idle": "2024-04-10T17:36:38.438643Z",
     "shell.execute_reply": "2024-04-10T17:36:38.437743Z",
     "shell.execute_reply.started": "2024-04-10T17:36:38.430145Z"
    },
    "id": "39273193-7dde-456a-a827-759c52031820"
   },
   "outputs": [],
   "source": [
    "# Filter out images that don't have duplicates (count = 1)  (Removed augmented images)\n",
    "# We will use this data to get validation set..\n",
    "df_undup = df[df['duplicates'] == 'unduplicated']\n",
    "df_undup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:38.44029Z",
     "iopub.status.busy": "2024-04-10T17:36:38.439953Z",
     "iopub.status.idle": "2024-04-10T17:36:38.450652Z",
     "shell.execute_reply": "2024-04-10T17:36:38.449629Z",
     "shell.execute_reply.started": "2024-04-10T17:36:38.440257Z"
    },
    "id": "e6ae5025-6eec-4616-a72a-9eb6bb6ad4b3"
   },
   "outputs": [],
   "source": [
    "# Create a val set using df as none of these images have augmented duplicates in the training set now..\n",
    "y = df_undup['cell_type_idx']\n",
    "_, df_val = train_test_split(df_undup, test_size=0.2, random_state=101, stratify=y)\n",
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:38.453561Z",
     "iopub.status.busy": "2024-04-10T17:36:38.453218Z",
     "iopub.status.idle": "2024-04-10T17:36:38.466065Z",
     "shell.execute_reply": "2024-04-10T17:36:38.465193Z",
     "shell.execute_reply.started": "2024-04-10T17:36:38.453532Z"
    },
    "id": "a38f0226-af35-4f6e-8ea2-053197731a73"
   },
   "outputs": [],
   "source": [
    "df_val['cell_type_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:38.467224Z",
     "iopub.status.busy": "2024-04-10T17:36:38.466994Z",
     "iopub.status.idle": "2024-04-10T17:36:38.474492Z",
     "shell.execute_reply": "2024-04-10T17:36:38.473671Z",
     "shell.execute_reply.started": "2024-04-10T17:36:38.467203Z"
    },
    "id": "c0255feb-0fc2-4bc8-a1cd-8c5e4f317007"
   },
   "outputs": [],
   "source": [
    "# Remove the validation rows from the original data to get training rows..\n",
    "\n",
    "# This function identifies if an image is part of the train or val set.\n",
    "def get_val_rows(x):\n",
    "    # create a list of all the lesion_id's in the val set\n",
    "    val_list = list(df_val['image'])\n",
    "    if str(x) in val_list:\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n",
    "# Identify train and val rows..\n",
    "# Create a new colum that is a copy of the image column\n",
    "df['train_or_val'] = df['image']\n",
    "\n",
    "# Apply the function to this new column\n",
    "df['train_or_val'] = df['train_or_val'].apply(get_val_rows)\n",
    "\n",
    "# Filter out training rows\n",
    "df_train = df[df['train_or_val'] == 'train']\n",
    "df_train = df_train.drop('train_or_val', axis = 1, inplace = False)\n",
    "print(len(df_train))\n",
    "print(len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:38.476005Z",
     "iopub.status.busy": "2024-04-10T17:36:38.475686Z",
     "iopub.status.idle": "2024-04-10T17:36:40.16033Z",
     "shell.execute_reply": "2024-04-10T17:36:40.15944Z",
     "shell.execute_reply.started": "2024-04-10T17:36:38.475971Z"
    },
    "id": "44d369f8-5367-4960-b1d2-a1bd1338c15d"
   },
   "outputs": [],
   "source": [
    "df_train['cell_type_idx'].value_counts()\n",
    "\n",
    "# Duplicate rows to balance the number of rows in 7 classes..\n",
    "data_aug_rate = [6.3,1.025,13,19.8,6.1,56.4,47.7]\n",
    "\n",
    "# Iterate over unique values of 'cell_type_idx'\n",
    "for i in df_train['cell_type_idx'].unique():\n",
    "\n",
    "    if data_aug_rate[i] > 1:\n",
    "\n",
    "        # Filter the DataFrame for the current value of 'cell_type_idx'\n",
    "        filtered_df = df_train[df_train['cell_type_idx'] == i]\n",
    "\n",
    "        # Duplicate rows based on the data augmentation rate for this value of 'cell_type_idx'\n",
    "        duplicated_rows = filtered_df.sample(frac=data_aug_rate[i] - 1, replace=True)\n",
    "\n",
    "        # Concatenate the original DataFrame with the duplicated rows\n",
    "        df_train = pd.concat([df_train, duplicated_rows], ignore_index=True)\n",
    "\n",
    "df_train['cell_type_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:40.161797Z",
     "iopub.status.busy": "2024-04-10T17:36:40.161516Z",
     "iopub.status.idle": "2024-04-10T17:36:40.191385Z",
     "shell.execute_reply": "2024-04-10T17:36:40.190558Z",
     "shell.execute_reply.started": "2024-04-10T17:36:40.161772Z"
    },
    "id": "0d2ccb27-b509-4770-a076-399dd8eb92e0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91da8f11-4bad-4b95-8186-f2f02ee1912e"
   },
   "source": [
    "# Split the test set again in a validation set and a true test set:\n",
    "\n",
    "df_val, df_test = train_test_split(df_val, test_size=0.5)\n",
    "df_train = df_train.reset_index()\n",
    "df_val = df_val.reset_index()\n",
    "df_test = df_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:40.193153Z",
     "iopub.status.busy": "2024-04-10T17:36:40.192571Z",
     "iopub.status.idle": "2024-04-10T17:36:40.198662Z",
     "shell.execute_reply": "2024-04-10T17:36:40.197712Z",
     "shell.execute_reply.started": "2024-04-10T17:36:40.19312Z"
    },
    "id": "GbVbuxAthSc4"
   },
   "outputs": [],
   "source": [
    "print(len(df_test))\n",
    "df_test['cell_type_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:40.200052Z",
     "iopub.status.busy": "2024-04-10T17:36:40.199774Z",
     "iopub.status.idle": "2024-04-10T17:36:40.215073Z",
     "shell.execute_reply": "2024-04-10T17:36:40.214269Z",
     "shell.execute_reply.started": "2024-04-10T17:36:40.200028Z"
    },
    "id": "a15096f3-dd3c-4619-9c72-60caca33a5ad"
   },
   "outputs": [],
   "source": [
    "# feature_extract is a boolean that defines finetuning or feature extracting.\n",
    "# If feature_extract = False, the model is finetuned and all model parameters are updated.\n",
    "# If feature_extract = True, only the last layer parameters are updated, the others remain fixed.\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:40.216933Z",
     "iopub.status.busy": "2024-04-10T17:36:40.216178Z",
     "iopub.status.idle": "2024-04-10T17:36:40.224656Z",
     "shell.execute_reply": "2024-04-10T17:36:40.223708Z",
     "shell.execute_reply.started": "2024-04-10T17:36:40.216899Z"
    },
    "id": "6a26a7c9-1a3d-49f6-a7dd-ce909f363a55"
   },
   "outputs": [],
   "source": [
    "\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"efficientnet\":\n",
    "        model_ft = models.efficientnet_b3(pretrained=True, progress=True)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        input_size = 224\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "322b282d-4c86-4376-addd-51cd043cfb49"
   },
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:36:40.226181Z",
     "iopub.status.busy": "2024-04-10T17:36:40.225856Z",
     "iopub.status.idle": "2024-04-10T17:36:40.233121Z",
     "shell.execute_reply": "2024-04-10T17:36:40.232064Z",
     "shell.execute_reply.started": "2024-04-10T17:36:40.226151Z"
    },
    "id": "7b36d853-5649-4dbd-b99e-d013008f7c90"
   },
   "outputs": [],
   "source": [
    "# Define a new model variable..\n",
    "\n",
    "model_name = \"efficientnet\"\n",
    "num_classes = 7\n",
    "feature_extract = False\n",
    "# Initialize the model\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Define the device:\n",
    "device = torch.device('cuda:0')\n",
    "# device = torch.device('cpu') # If using cpu\n",
    "# Put the model on the device:\n",
    "model = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:31:45.931238Z",
     "iopub.status.busy": "2024-04-10T18:31:45.930563Z",
     "iopub.status.idle": "2024-04-10T18:31:45.937774Z",
     "shell.execute_reply": "2024-04-10T18:31:45.936816Z",
     "shell.execute_reply.started": "2024-04-10T18:31:45.931147Z"
    },
    "id": "b2430227-8d6c-45a3-b73b-a7280f5091e6"
   },
   "outputs": [],
   "source": [
    "# define the transformation of the train images.\n",
    "train_transform = transforms.Compose([transforms.Resize((input_size,input_size)),transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomVerticalFlip(),\n",
    "                                      transforms.RandomRotation(20),\n",
    "                                      transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(norm_mean, norm_std)])\n",
    "\n",
    "\n",
    "# define the transformation of the val images.\n",
    "val_transform = transforms.Compose([transforms.Resize((input_size,input_size)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(norm_mean, norm_std)])\n",
    "\n",
    "# define the transformation of the test images.\n",
    "test_transform = transforms.Compose([transforms.Resize((input_size,input_size)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                    transforms.Normalize(norm_mean, norm_std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:31:46.100694Z",
     "iopub.status.busy": "2024-04-10T18:31:46.100281Z",
     "iopub.status.idle": "2024-04-10T18:31:46.107116Z",
     "shell.execute_reply": "2024-04-10T18:31:46.106232Z",
     "shell.execute_reply.started": "2024-04-10T18:31:46.100663Z"
    },
    "id": "pDKXPsvtLlCW"
   },
   "outputs": [],
   "source": [
    "# Define a pytorch dataloader for dataset..\n",
    "class HAM10000(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load data and get label\n",
    "        X = Image.open(self.df['path'][index])\n",
    "        y = torch.tensor(int(self.df['cell_type_idx'][index]))\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:31:46.275153Z",
     "iopub.status.busy": "2024-04-10T18:31:46.274429Z",
     "iopub.status.idle": "2024-04-10T18:31:46.662563Z",
     "shell.execute_reply": "2024-04-10T18:31:46.661774Z",
     "shell.execute_reply.started": "2024-04-10T18:31:46.275115Z"
    },
    "id": "269c3eef-51cc-4816-b76f-7b799f1ae2ef"
   },
   "outputs": [],
   "source": [
    "# Define the training set using the table train_df and using the defined transitions (train_transform)\n",
    "training_set = HAM10000(df_train, transform=train_transform)\n",
    "train_loader = DataLoader(training_set, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "# Same for the validation set:\n",
    "validation_set = HAM10000(df_val, transform=train_transform)\n",
    "val_loader = DataLoader(validation_set, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Same for the test set:\n",
    "test_set = HAM10000(df_test, transform=train_transform)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc6ed264-20e3-4738-a852-e56fa710caba"
   },
   "source": [
    "# this function is used during training process, to calculate the loss and accuracy\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:31:46.664617Z",
     "iopub.status.busy": "2024-04-10T18:31:46.664217Z",
     "iopub.status.idle": "2024-04-10T18:31:46.672553Z",
     "shell.execute_reply": "2024-04-10T18:31:46.671405Z",
     "shell.execute_reply.started": "2024-04-10T18:31:46.664583Z"
    },
    "id": "7523d804-777c-45d9-9c5e-fea359dca2d6"
   },
   "outputs": [],
   "source": [
    "total_loss_train, total_acc_train = [],[]\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch, threshold_batch):\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "    for i, data in enumerate(train_loader):\n",
    "\n",
    "        if threshold_batch and i>= threshold_batch:\n",
    "            break\n",
    "\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
    "                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:31:46.785506Z",
     "iopub.status.busy": "2024-04-10T18:31:46.785004Z",
     "iopub.status.idle": "2024-04-10T18:31:46.79183Z",
     "shell.execute_reply": "2024-04-10T18:31:46.790861Z",
     "shell.execute_reply.started": "2024-04-10T18:31:46.78548Z"
    },
    "id": "c770294a-3192-437e-a6ea-491246ccda2a"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, optimizer, epoch):\n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "\n",
    "    total_val_loss = []\n",
    "    total_val_acc = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(val_loader)):\n",
    "\n",
    "            images, labels = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "            if (i + 1) % 3 == 0:\n",
    "                total_val_acc.append(val_acc.avg)\n",
    "                total_val_loss.append(val_loss.avg)\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "    return  total_val_loss , total_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:31:46.948295Z",
     "iopub.status.busy": "2024-04-10T18:31:46.947505Z",
     "iopub.status.idle": "2024-04-10T18:31:46.954463Z",
     "shell.execute_reply": "2024-04-10T18:31:46.953403Z",
     "shell.execute_reply.started": "2024-04-10T18:31:46.948262Z"
    },
    "id": "03bf71e2-b9f3-4d3e-b41f-5d60ee984b66"
   },
   "outputs": [],
   "source": [
    "# Start Training..\n",
    "def train_model(epoch_num, lr, optimizer_func = optim.Adam, threshold_batch = None, criterion = nn.CrossEntropyLoss()):\n",
    "\n",
    "    best_val_acc = 0\n",
    "    total_loss_val, total_acc_val = [],[]\n",
    "    for epoch in tqdm(range(1, epoch_num+1)):\n",
    "\n",
    "        # set optimizer and loss function\n",
    "        optimizer = optimizer_func(model.parameters(), lr= lr)\n",
    "        criterion = criterion.to(device)\n",
    "\n",
    "        loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch, threshold_batch)\n",
    "        loss_val, acc_val = validate(val_loader, model, criterion , optimizer, epoch)\n",
    "        total_loss_val += loss_val\n",
    "        total_acc_val += acc_val\n",
    "    return total_loss_val, total_acc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:31:47.11857Z",
     "iopub.status.busy": "2024-04-10T18:31:47.117938Z",
     "iopub.status.idle": "2024-04-10T18:31:47.125272Z",
     "shell.execute_reply": "2024-04-10T18:31:47.124228Z",
     "shell.execute_reply.started": "2024-04-10T18:31:47.118542Z"
    },
    "id": "3364d0cb-439f-4364-895d-f589cf8caff6"
   },
   "outputs": [],
   "source": [
    "# Store Training data..\n",
    "total_loss_val, total_acc_val = [],[]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:31:47.26173Z",
     "iopub.status.busy": "2024-04-10T18:31:47.260935Z",
     "iopub.status.idle": "2024-04-10T18:31:47.271099Z",
     "shell.execute_reply": "2024-04-10T18:31:47.270137Z",
     "shell.execute_reply.started": "2024-04-10T18:31:47.261699Z"
    },
    "id": "04368d6e-67ea-4322-970f-f23baec8d359"
   },
   "outputs": [],
   "source": [
    "# Training - 1st\n",
    "data = train_model(1,1e-3)\n",
    "total_loss_val += data[0]\n",
    "total_acc_val += data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:31:47.398561Z",
     "iopub.status.busy": "2024-04-10T18:31:47.397953Z",
     "iopub.status.idle": "2024-04-10T18:31:47.407259Z",
     "shell.execute_reply": "2024-04-10T18:31:47.406405Z",
     "shell.execute_reply.started": "2024-04-10T18:31:47.398531Z"
    },
    "id": "0cf9d7a6-6a20-4285-96ef-6115387ea8b8"
   },
   "outputs": [],
   "source": [
    "# Check results on test dataset..\n",
    "validate(test_loader, model, criterion, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:31:47.554751Z",
     "iopub.status.busy": "2024-04-10T18:31:47.554483Z",
     "iopub.status.idle": "2024-04-10T18:31:47.561552Z",
     "shell.execute_reply": "2024-04-10T18:31:47.560519Z",
     "shell.execute_reply.started": "2024-04-10T18:31:47.554727Z"
    },
    "id": "5a283e24-b1ee-40e9-9d81-baa3054d9afa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training - 2nd..\n",
    "train_model(1,1e-5,threshold_batch = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:31:47.998278Z",
     "iopub.status.busy": "2024-04-10T18:31:47.997545Z",
     "iopub.status.idle": "2024-04-10T18:31:48.002778Z",
     "shell.execute_reply": "2024-04-10T18:31:48.001774Z",
     "shell.execute_reply.started": "2024-04-10T18:31:47.998246Z"
    },
    "id": "BA811jIahSc-"
   },
   "outputs": [],
   "source": [
    "# Check results on test dataset..\n",
    "validate(test_loader, model, criterion, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:31:48.330439Z",
     "iopub.status.busy": "2024-04-10T18:31:48.329619Z",
     "iopub.status.idle": "2024-04-10T18:36:56.327767Z",
     "shell.execute_reply": "2024-04-10T18:36:56.32659Z",
     "shell.execute_reply.started": "2024-04-10T18:31:48.330407Z"
    },
    "id": "j-ljPPn6hSc-"
   },
   "outputs": [],
   "source": [
    "# Training - 3rd..\n",
    "train_model(1,1e-5,threshold_batch = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:36:56.331048Z",
     "iopub.status.busy": "2024-04-10T18:36:56.330277Z",
     "iopub.status.idle": "2024-04-10T18:37:00.306007Z",
     "shell.execute_reply": "2024-04-10T18:37:00.304954Z",
     "shell.execute_reply.started": "2024-04-10T18:36:56.331005Z"
    },
    "id": "YeKk7OYRhSc-"
   },
   "outputs": [],
   "source": [
    "# Check results on test dataset..\n",
    "validate(test_loader, model, criterion, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:37:00.307707Z",
     "iopub.status.busy": "2024-04-10T18:37:00.307387Z",
     "iopub.status.idle": "2024-04-10T18:38:16.293424Z",
     "shell.execute_reply": "2024-04-10T18:38:16.292298Z",
     "shell.execute_reply.started": "2024-04-10T18:37:00.307676Z"
    },
    "id": "wWf_PYiohSc-"
   },
   "outputs": [],
   "source": [
    "total_loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:38:16.297403Z",
     "iopub.status.busy": "2024-04-10T18:38:16.296688Z",
     "iopub.status.idle": "2024-04-10T18:38:20.140585Z",
     "shell.execute_reply": "2024-04-10T18:38:20.139511Z",
     "shell.execute_reply.started": "2024-04-10T18:38:16.297343Z"
    },
    "id": "01d-6bE4hSc-"
   },
   "outputs": [],
   "source": [
    "# Analysing accuracy and loss of validation data over the model..\n",
    "\n",
    "fig = plt.figure(num = 1)\n",
    "fig2 = fig.add_subplot(1,1,1)\n",
    "fig2.plot(total_acc_val, label = 'validation accuracy')\n",
    "fig2.plot(total_loss_val, label = 'validation loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:38:20.142863Z",
     "iopub.status.busy": "2024-04-10T18:38:20.142559Z",
     "iopub.status.idle": "2024-04-10T18:39:36.460623Z",
     "shell.execute_reply": "2024-04-10T18:39:36.459414Z",
     "shell.execute_reply.started": "2024-04-10T18:38:20.142835Z"
    },
    "id": "crK7vz7ehSc_"
   },
   "outputs": [],
   "source": [
    "# Analysing accuracy and loss of training data over the model..\n",
    "\n",
    "fig = plt.figure(num=1)\n",
    "fig1 = fig.add_subplot(1,1,1)\n",
    "fig1.plot(total_acc_train, label = 'training accuracy')\n",
    "fig1.plot(total_loss_train, label = 'training loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:39:36.462566Z",
     "iopub.status.busy": "2024-04-10T18:39:36.462204Z",
     "iopub.status.idle": "2024-04-10T18:39:40.382079Z",
     "shell.execute_reply": "2024-04-10T18:39:40.381039Z",
     "shell.execute_reply.started": "2024-04-10T18:39:36.462534Z"
    },
    "id": "PWDZJOXChSc_"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udCRmxXvhSc_"
   },
   "source": [
    "# This is Validation data evaluation\n",
    "\n",
    "model.eval()\n",
    "y_label = []\n",
    "y_predict = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(val_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        images = Variable(images).to(device)\n",
    "        outputs = model(images)\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        y_label.extend(labels.cpu().numpy())\n",
    "        y_predict.extend(np.squeeze(prediction.cpu().numpy().T))\n",
    "\n",
    "# compute the confusion matrix for the validation matrix..\n",
    "confusion_mtx = confusion_matrix(y_label, y_predict)\n",
    "# plot the confusion matrix..\n",
    "plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'nv', 'vasc','mel']\n",
    "plot_confusion_matrix(confusion_mtx, plot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:39:40.383756Z",
     "iopub.status.busy": "2024-04-10T18:39:40.383464Z",
     "iopub.status.idle": "2024-04-10T18:39:40.390144Z",
     "shell.execute_reply": "2024-04-10T18:39:40.389091Z",
     "shell.execute_reply.started": "2024-04-10T18:39:40.383728Z"
    },
    "id": "_d6Mq4qLhSc_"
   },
   "outputs": [],
   "source": [
    "# This is test data evaluation\n",
    "\n",
    "model.eval()\n",
    "test_y_label = []\n",
    "test_y_predict = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        images = Variable(images).to(device)\n",
    "        outputs = model(images)\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        test_y_label.extend(labels.cpu().numpy())\n",
    "        test_y_predict.extend(np.squeeze(prediction.cpu().numpy().T))\n",
    "\n",
    "# compute the confusion matrix for the test data..\n",
    "confusion_mtx_test = confusion_matrix(test_y_label, test_y_predict)\n",
    "\n",
    "# plot the confusion matrix\n",
    "plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'nv', 'vasc','mel']\n",
    "plot_confusion_matrix(confusion_mtx, plot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:39:40.391643Z",
     "iopub.status.busy": "2024-04-10T18:39:40.391337Z",
     "iopub.status.idle": "2024-04-10T18:39:40.664408Z",
     "shell.execute_reply": "2024-04-10T18:39:40.663434Z",
     "shell.execute_reply.started": "2024-04-10T18:39:40.391619Z"
    },
    "id": "ZX5DKWTBhSc_"
   },
   "outputs": [],
   "source": [
    "# Generate a validation classification report\n",
    "report = classification_report(y_label, y_predict, target_names=plot_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:39:40.666244Z",
     "iopub.status.busy": "2024-04-10T18:39:40.665856Z",
     "iopub.status.idle": "2024-04-10T18:39:40.941244Z",
     "shell.execute_reply": "2024-04-10T18:39:40.940346Z",
     "shell.execute_reply.started": "2024-04-10T18:39:40.666207Z"
    },
    "id": "8GTViITMhSc_"
   },
   "outputs": [],
   "source": [
    "# Generate a test classification report\n",
    "report = classification_report(test_y_label, test_y_predict, target_names=plot_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:39:40.944902Z",
     "iopub.status.busy": "2024-04-10T18:39:40.94453Z",
     "iopub.status.idle": "2024-04-10T18:39:40.954264Z",
     "shell.execute_reply": "2024-04-10T18:39:40.953312Z",
     "shell.execute_reply.started": "2024-04-10T18:39:40.944874Z"
    },
    "id": "3EBQiOxohSc_"
   },
   "outputs": [],
   "source": [
    "# True vs Incoorect classified analysis for validation data\n",
    "\n",
    "label_frac_error = 1 - np.diag(confusion_mtx) / np.sum(confusion_mtx, axis=1)\n",
    "plt.bar(np.arange(7),label_frac_error)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Fraction classified incorrectly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:39:40.955781Z",
     "iopub.status.busy": "2024-04-10T18:39:40.955508Z",
     "iopub.status.idle": "2024-04-10T18:39:45.324192Z",
     "shell.execute_reply": "2024-04-10T18:39:45.323116Z",
     "shell.execute_reply.started": "2024-04-10T18:39:40.955757Z"
    },
    "id": "Ecj4dKyThSc_"
   },
   "outputs": [],
   "source": [
    "# True vs Incoorect classified analysis for test data\n",
    "\n",
    "label_frac_error = 1 - np.diag(confusion_mtx_test) / np.sum(confusion_mtx_test, axis=1)\n",
    "plt.bar(np.arange(7),label_frac_error)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Fraction classified incorrectly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:39:45.326684Z",
     "iopub.status.busy": "2024-04-10T18:39:45.325945Z",
     "iopub.status.idle": "2024-04-10T18:39:49.868952Z",
     "shell.execute_reply": "2024-04-10T18:39:49.867794Z",
     "shell.execute_reply.started": "2024-04-10T18:39:45.32664Z"
    },
    "id": "aTgzAH_ZhSc_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:39:49.870523Z",
     "iopub.status.busy": "2024-04-10T18:39:49.870201Z",
     "iopub.status.idle": "2024-04-10T18:39:49.887646Z",
     "shell.execute_reply": "2024-04-10T18:39:49.886729Z",
     "shell.execute_reply.started": "2024-04-10T18:39:49.870485Z"
    },
    "id": "XMYTu0BxhSc_"
   },
   "outputs": [],
   "source": [
    "# Get data..\n",
    "img_data_dir = data_dir + r\"/KCDH2024_Test_Input/KCDH2024_Test_Input\"\n",
    "all_image_path = glob(os.path.join(img_data_dir, '*.jpg'))\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}  # key - image filename,   value - path to image\n",
    "len(imageid_path_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:39:49.888819Z",
     "iopub.status.busy": "2024-04-10T18:39:49.888576Z",
     "iopub.status.idle": "2024-04-10T18:39:49.904506Z",
     "shell.execute_reply": "2024-04-10T18:39:49.903595Z",
     "shell.execute_reply.started": "2024-04-10T18:39:49.888797Z"
    },
    "id": "2eN-XERMhSc_"
   },
   "outputs": [],
   "source": [
    "# Header of txt file..\n",
    "text = \"ID,Class\\n\"\n",
    "\n",
    "# Rows ..\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for imagename, path in tqdm(imageid_path_dict.items()):\n",
    "         X = Image.open(path)\n",
    "         X = test_transform(X)\n",
    "         X = Variable(X).to(device)\n",
    "         output = model(X.unsqueeze(0))\n",
    "         prediction = output.max(1, keepdim=True)[1].item()\n",
    "         text += f\"{imagename},{prediction}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:39:49.906503Z",
     "iopub.status.busy": "2024-04-10T18:39:49.905709Z",
     "iopub.status.idle": "2024-04-10T18:39:50.207156Z",
     "shell.execute_reply": "2024-04-10T18:39:50.206172Z",
     "shell.execute_reply.started": "2024-04-10T18:39:49.906468Z"
    },
    "id": "9zWOl2oqhSdA"
   },
   "outputs": [],
   "source": [
    "with open(f'predictions.csv', 'w') as txtfile:\n",
    "    txtfile.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:39:50.208874Z",
     "iopub.status.busy": "2024-04-10T18:39:50.208573Z",
     "iopub.status.idle": "2024-04-10T18:39:50.473987Z",
     "shell.execute_reply": "2024-04-10T18:39:50.472995Z",
     "shell.execute_reply.started": "2024-04-10T18:39:50.208847Z"
    },
    "id": "w6Mq-e-3hSdA"
   },
   "outputs": [],
   "source": [
    "\n",
    "# TYPES OF METRICS\n",
    "# For scientific completeness, predicted responses will also have the following metrics computed (comparing prediction vs. ground truth) for each image:\n",
    "# 1. Accuracy\n",
    "# 2. Area under the receiver operating characteristic curve (AUC)\n",
    "# 3. Mean average precision\n",
    "# 4. F1 score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3H7BIKDhSdA"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
    "\n",
    "# Assuming `y_true` is the ground truth and `y_pred` is the predicted values\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    # Convert predictions to binary if necessary\n",
    "    # For multi-class, the y_pred and y_true should be in one-hot encoded form or use appropriate method\n",
    "    auc = roc_auc_score(y_true, y_pred, multi_class='ovo', average='macro')\n",
    "    mean_ap = average_precision_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"AUC:\", auc)\n",
    "    print(\"Mean Average Precision:\", mean_ap)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "# Example usage:\n",
    "# compute_metrics(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJSMtp87hSdA"
   },
   "source": [
    "<h1> Predictions... </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T08:05:40.008301Z",
     "iopub.status.busy": "2024-03-16T08:05:40.007377Z",
     "iopub.status.idle": "2024-03-16T08:05:40.028668Z",
     "shell.execute_reply": "2024-03-16T08:05:40.027812Z",
     "shell.execute_reply.started": "2024-03-16T08:05:40.008265Z"
    },
    "id": "c6790879-389d-4ff7-93d4-ddfe30320f3f"
   },
   "outputs": [],
   "source": [
    "# Get data..\n",
    "img_data_dir = data_dir + r\"/KCDH2024_Test_Input/KCDH2024_Test_Input\"\n",
    "all_image_path = glob(os.path.join(img_data_dir, '*.jpg'))\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}  # key - image filename,   value - path to image\n",
    "len(imageid_path_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T08:09:00.394788Z",
     "iopub.status.busy": "2024-03-16T08:09:00.393768Z",
     "iopub.status.idle": "2024-03-16T08:09:39.802024Z",
     "shell.execute_reply": "2024-03-16T08:09:39.801142Z",
     "shell.execute_reply.started": "2024-03-16T08:09:00.394732Z"
    },
    "id": "_-Lu49i7hSdA"
   },
   "outputs": [],
   "source": [
    "# Header of txt file..\n",
    "text = \"ID,Class\\n\"\n",
    "\n",
    "# Rows ..\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for imagename, path in tqdm(imageid_path_dict.items()):\n",
    "         X = Image.open(path)\n",
    "         X = test_transform(X)\n",
    "         X = Variable(X).to(device)\n",
    "         output = model(X.unsqueeze(0))\n",
    "         prediction = output.max(1, keepdim=True)[1].item()\n",
    "         text += f\"{imagename},{prediction}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T08:10:05.499444Z",
     "iopub.status.busy": "2024-03-16T08:10:05.499061Z",
     "iopub.status.idle": "2024-03-16T08:10:05.504731Z",
     "shell.execute_reply": "2024-03-16T08:10:05.50379Z",
     "shell.execute_reply.started": "2024-03-16T08:10:05.499392Z"
    },
    "id": "EC37DiUghSdA"
   },
   "outputs": [],
   "source": [
    "with open(f'predictions.csv', 'w') as txtfile:\n",
    "    txtfile.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gVOSy2PhSdA"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "Using EfficientNet",
   "provenance": [
    {
     "file_id": "https://storage.googleapis.com/kaggle-colab-exported-notebooks/using-efficientnet-9cd6ddc6-3fe7-47f1-be22-d3dc1b1fb7c9.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20240731/auto/storage/goog4_request&X-Goog-Date=20240731T160003Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=603a33155dd6262f517a02ce7ce4ecf9a3788032270a2470580b243e77a13d00e3cdb8e76585f85d6d66da38236dacf729fd2075ec679cc1e99e6e305c8190d2e70db6d5d70500f1fa788de0be4e9bb46276b0e046bde27864e554945b0c974113a094203622e267357db5f266e344a0c913fc96aff0124f52faf772765b855579883d1e7d1e584702feb20cf8712e412d32500a95df08679c57b04d84242c36dcaa8f52e060e3e35e22ab2a9783326c62f469283f48fdc88862e2c44efd79eb1d3e8ce4447ab1871950852e6e0e639405e9fb2041f5633fb73b868da0dfcecbb866f07a0d1665e30cc42eee871768df0c2993952c6852a1b5768a48215e9701",
     "timestamp": 1722441632510
    },
    {
     "file_id": "1FSHVePF9HJAdM2oHmy_Twcvd3hcR7zel",
     "timestamp": 1710422730566
    }
   ]
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7895811,
     "sourceId": 71608,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
